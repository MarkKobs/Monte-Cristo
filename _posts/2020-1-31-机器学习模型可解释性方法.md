---
title: 机器学习模型可解释性方法
date: 2020-01-31 11:41:00 
tags: 可解释机器学习
category: 机器学习
---
这篇文章为浙江大学计算机科学与技术学院网络空间安全研究中心的纪守领、李进锋、杜天宇等人发表于计算机研究与发展上的研究综述文章。

# 机器学习的可解释性
1. 不同的学者对于**可解释性**的定义不同。
2. 在数据挖掘和机器学习的场景中，可解释性被定义为向人类解释或以呈现可理解的术语的能力。

## 自上而下的机器学习
- 它（“解释”）是规则和假设的基石。
- 它（“解释”）能验证假设是否稳健。
- 它（“解释”）能判断所定义的规则是否适合任务。

## 自下而上的机器学习
所谓的自下而上的机器学习，即给定一批数据，通过最小化学习误差，让模型自动地学习输入数据和输出类别之间的**映射关系**。
- 它旨在帮助人们理解机器学习模型是如何学习的。
- 它能判断它所做的决策是否可靠。

## 一条公理
复杂性、准确性、可解释性这三者有内在关联性，如果用1表示高，0表示低，那么只可能有110、001，复杂性与准确性正相关，可解释性与之相对。

# 可解释的分类
大体可以分为两类
1. 事前（ante-hoc）可解释
2. 事后（post-hoc）可解释

## 事前可解释
事前可解释表示模型自带解释性，例如一些简单的模型：
1. 朴素贝叶斯
2. 线性回归
3. 决策树
4. 基于规则的模型

### 广义加权模型
结合线性的可解释，与非线性的准确性。**g(x)=f1(x1)+f2(x2)+...+fn(xn)**
- lou等人：基于有限大小的梯度提升的加性模型方法。
- Ravikmar：稀疏线性建模和加性非参数回归。
- Poulin：提供对加性模型的图形化解释。

### 注意力机制
**神经网络模型由于模型结构复杂，透明度低，因此额外引入注意力机制**
- Bahadanu：自然语言处理。
- Yang等人：文本分类、情感分析。
- Xu等人：看图说话、推荐系统。

## 事后可解释性
发生在模型训练之后，对于一个给定的训练好的学习模型，post-hoc可解释性旨在利用解释方法或**构建解释模型**，解释学习模型的工作机制，决策行为和决策依据。

### 事后可解释性分类
1. 全局解释
    1. **规则提取**
        1. 针对树融合模型的规则提取
        2. 针对神经网络的规则提取
    2. 模型蒸馏
    3. 激活最大化
2. 局部解释
    1. 敏感性分析
    2. 局部近似
    3. 反向传播
    4. 特征反演
    5. 类激活映射

## 机器学习可解释性应用
1. 模型验证
2. 模型诊断
3. 辅助分析
4. 知识发现